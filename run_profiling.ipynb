{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "üìù Description of this run:  Update pipeline to log output of job as well.\n",
      "üîß What did you change?  Added a step in the pipeline to bring back the job output and log as artifact.\n",
      "üí° What do you expect to happen?  Should get logged in the Artifacts tab.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-04-17 12:16:37.688\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m53\u001b[0m - \u001b[1mInitiating push to remote for CUDA file.\u001b[0m\n",
      "sending incremental file list\n",
      "\n",
      "sent 72 bytes  received 12 bytes  56.00 bytes/sec\n",
      "total size is 11,456  speedup is 136.38\n",
      "\u001b[32m2025-04-17 12:16:38.456\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m92\u001b[0m - \u001b[1mSlurm script written to 'submit_job.sh'\u001b[0m\n",
      "\u001b[32m2025-04-17 12:16:38.456\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mSyncing slurm script to remote...\u001b[0m\n",
      "sending incremental file list\n",
      "submit_job.sh\n",
      "\n",
      "sent 416 bytes  received 41 bytes  914.00 bytes/sec\n",
      "total size is 533  speedup is 1.17\n",
      "\u001b[32m2025-04-17 12:16:39.042\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m101\u001b[0m - \u001b[1mSubmitting slurm job...\u001b[0m\n",
      "Submitted batch job 66908893\n",
      "Connection to nt.swin.edu.au closed.\n",
      "\u001b[32m2025-04-17 12:17:53.564\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m109\u001b[0m - \u001b[1mPulling back results...\u001b[0m\n",
      "receiving incremental file list\n",
      "profile_20250417_1216.csv\n",
      "\n",
      "sent 43 bytes  received 3,674 bytes  2,478.00 bytes/sec\n",
      "total size is 20,975  speedup is 5.64\n",
      "receiving incremental file list\n",
      "profile_20250417_1216.ncu-rep\n",
      "\n",
      "sent 43 bytes  received 220,105 bytes  440,296.00 bytes/sec\n",
      "total size is 1,016,023  speedup is 4.62\n",
      "receiving incremental file list\n",
      "profile_log_20250417_1216.txt\n",
      "\n",
      "sent 43 bytes  received 1,184 bytes  818.00 bytes/sec\n",
      "total size is 3,117  speedup is 2.54\n",
      "\u001b[32m2025-04-17 12:17:55.493\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m176\u001b[0m - \u001b[1mStarting MLFlow run...\u001b[0m\n",
      "\u001b[32m2025-04-17 12:17:55.528\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m193\u001b[0m - \u001b[1mLogging parameters...\u001b[0m\n",
      "\u001b[32m2025-04-17 12:17:55.534\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m197\u001b[0m - \u001b[1mLogging metrics...\u001b[0m\n",
      "üèÉ View run intrigued-jay-694 at: http://localhost:5000/#/experiments/631611066622488177/runs/a7f5a3cb75cd492ca092d4d6127dbc5a\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/631611066622488177\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jay/projects/cuda-beamformer/profile_with_mlflow.py\", line 205, in <module>\n",
      "    mlflow.log_artifact(os.path.join(LOCAL_OUTPUT_DIR, params['JOB_OUTPUT_FILE_NAME']))\n",
      "KeyError: 'JOB_OUTPUT_FILE_NAME'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "description = input(\"üìù Description of this run: \")\n",
    "change = input(\"üîß What did you change? \")\n",
    "hypothesis = input(\"üí° What do you expect to happen? \")\n",
    "\n",
    "!python profile_with_mlflow.py \"{description}\" \"{change}\" \"{hypothesis}\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
